{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import numpy.fft as fourier\n",
    "log2 = np.log2\n",
    "log10 = np.log10\n",
    "real = np.real\n",
    "imag = np.imag \n",
    "pi = np.pi\n",
    "\n",
    "def combined_analysis(s_df, dt, NfDec, max_seg_period):\n",
    "\n",
    "    freqs_list = []\n",
    "    ensemble_ave_list = []\n",
    "    ensemble_errors_list = []\n",
    "    \n",
    "    freqs_binned_list = []\n",
    "    PSD_binned_list = []\n",
    "    dPSD_list = []\n",
    "\n",
    "    Dphi_list = []\n",
    "    freqs_lag_list = []\n",
    "    taus_list = []\n",
    "    dtaus_list = []\n",
    "    gamma2_list = []\n",
    "\n",
    "    # Call ensemble_averaging for each row in s_df\n",
    "    for index, row in s_df.iterrows():\n",
    "        s = row.values\n",
    "\n",
    "        freqs, ensemble_ave, ensemble_errors = ensemble_averaging(s, dt, max_seg_period)\n",
    "\n",
    "        freqs_list.append(freqs)\n",
    "        ensemble_ave_list.append(ensemble_ave)\n",
    "        ensemble_errors_list.append(ensemble_errors)\n",
    "\n",
    "    # Call binned_spectrum for each row in s_df\n",
    "    for index, row in s_df.iterrows():\n",
    "        s = row.values\n",
    "        freqs_binned, PSD_binned, dPSD = binned_spectrum(s, dt, NfDec, max_seg_period)\n",
    "    \n",
    "        freqs_binned_list.append(freqs_binned)\n",
    "        PSD_binned_list.append(PSD_binned)\n",
    "        dPSD_list.append(dPSD)\n",
    "\n",
    "    # Call FourierLag for each row in s_df excluding the first row\n",
    "    for index,row in s_df.iterrows():\n",
    "        s = s_df.iloc[0].values\n",
    "        h = row.values\n",
    "        Dphi, freqs, taus, dtaus, gamma2 = FourierLag(s, h, dt, NfDec, max_seg_period)\n",
    "\n",
    "        Dphi_list.append(Dphi)\n",
    "        freqs_lag_list.append(freqs)\n",
    "        taus_list.append(taus)\n",
    "        dtaus_list.append(dtaus)\n",
    "        \n",
    "        gamma2_list.append(gamma2)\n",
    "\n",
    "    # Create DataFrames from the collected results\n",
    "    freqs_df = pd.DataFrame(freqs_list, index=s_df.index)\n",
    "    ensemble_ave_df = pd.DataFrame(ensemble_ave_list, index=s_df.index)\n",
    "    ensemble_errors_df = pd.DataFrame(ensemble_errors_list, index=s_df.index)\n",
    "    \n",
    "    freqs_binned_df = pd.DataFrame(freqs_binned_list, index=s_df.index)\n",
    "    PSD_binned_df = pd.DataFrame(PSD_binned_list, index=s_df.index)\n",
    "    dPSD_df = pd.DataFrame(dPSD_list, index=s_df.index)\n",
    "\n",
    "    Dphi_df = pd.DataFrame(Dphi_list, index=s_df.index)\n",
    "    freqs_lag_df = pd.DataFrame(freqs_lag_list, index=s_df.index)\n",
    "    taus_df = pd.DataFrame(taus_list, index=s_df.index)\n",
    "    dtaus_df = pd.DataFrame(dtaus_list, index=s_df.index)\n",
    "    gamma2_df = pd.DataFrame(gamma2_list, index=s_df.index)\n",
    "\n",
    "    return (freqs_df, ensemble_ave_df, ensemble_errors_df, freqs_binned_df, PSD_binned_df, dPSD_df, Dphi_df, \n",
    "            freqs_lag_df, taus_df, dtaus_df, gamma2_df)\n",
    "\n",
    "def ensemble_averaging(s,dt, max_seg_period):\n",
    "    '''This function takes an input curve, s, and a segment length, max_seg_period, (which has the same units as the time binning, dt - in my case, seconds).\n",
    "    It first slices the input curve into M segments of length di, where di is the largest power of 2 such that di < max_seg_period/dt.\n",
    "    Ensuring that the segments are a power of 2 in length allows the fast fourier transform to work efficiently.\n",
    "    \n",
    "    For each slice, it then computes the periodogram (raw PSD) which will have maximum frequency 1/(2*dt), and minimum frequency 1/(di*dt).\n",
    "    In each frequency bin, it then takes the mean of the periodograms at this frequency, to yield the ensemble averaged PSD.\n",
    "    This output is then ready for logarithmic rebinning.\n",
    "    '''    \n",
    "    di = 2 ** int(log2(max_seg_period/dt)) # Slice length.\n",
    "    freqs = abs(fourier.fftfreq(di, dt))[1:int(di/2+1)] # Raw frequencies of the sliced data.\n",
    "\n",
    "    M =  int(len(s)/di) # Number of slices.\n",
    "    s = s[0: M*di] #  We discard the final few data points such that each segment has length di.\n",
    "    s.shape = (M, di) # Reshape our data so that we can iterate over rows (segments).\n",
    "\n",
    "    periodograms = np.zeros((M, int(di/2)), dtype = 'float') # Placeholder array.\n",
    " \n",
    "    for j in range(M):\n",
    "        S = fourier.fft(s[j]) / di # Fourier transform of segment j.\n",
    "        raw_periodogram_j = (np.conj(S) * S) * di *2* dt / np.average(s[j])**2 # Raw periodogram of segment j.\n",
    "        periodograms[j] = abs(raw_periodogram_j)[1:int(di/2+1)] #Take only the positive side of the raw periodogram as it is symmetric about zero and the lower half will change the norm incorrectly.\n",
    "    ensemble_ave = periodograms.sum(axis = 0)/M # Average all of the periodograms for each frequency bin and voila.\n",
    "    ensemble_errors = np.sqrt(np.var(periodograms, axis=0, ddof = 1)) / np.sqrt(M) # Compute the ensemble errors.\n",
    "\n",
    "    return freqs, ensemble_ave, ensemble_errors\n",
    "\n",
    "def binned_spectrum(s,dt, NfDec, max_seg_period):\n",
    "    '''The function takes an input, s, runs it through the ensemble averaging function, and then rebins the resulting power spectrum logarithmically, greatly reducing the noise.\n",
    "    The parameter NfDec determines the number of logarithmic bins per frequency decaed. It can be turned up if you want a noisier power spectrum with more features, or\n",
    "    down for a less noisy power spectrum, although this may mask interesting features. Feel free to tune it until your output is pretty.\n",
    "    max_seg_period is explained in the ensemble_averaging comments.'''\n",
    "    \n",
    "    A = ensemble_averaging(s,dt, max_seg_period = max_seg_period)\n",
    "    freqs, ensemble_ave, ensemble_errors  = A[0], A[1], A[2] # First ensemble average the input curve to smooth out anomalous fourier features.\n",
    "\n",
    "    fbins = np.logspace(log10(freqs[0]), log10(freqs[-1]), int(log10(freqs[-1]) - log10(freqs[0])) * NfDec) # We define the logarithmic bins for our output PSD.\n",
    "    freqs_binned = np.array((), dtype = 'float') # Placeholders\n",
    "    PSD_binned = np.array((), dtype = 'float')\n",
    "    dPSD = np.array((), dtype = 'float')\n",
    "    inds = np.digitize(freqs, fbins) # Assign frequencies to their parent bins and store the indices.\n",
    "    \n",
    "    count =0\n",
    "    for i in range(1, inds[-1]):\n",
    "        if i in inds:\n",
    "            i_min, i_max = min(np.argwhere(inds == i))[0], max(np.argwhere(inds==i))[0] # Take the min and max index (in freqs) for each bin in fbins.\n",
    "            if(i_min==i_max and count==0):\n",
    "                count+=1\n",
    "            elif(count > 0):\n",
    "                freqs_binned = np.append(freqs_binned, (freqs[i_min-count] + freqs[i_max])/2) # The average frequency in each fbin will then be the bin centre.\n",
    "                PSD_binned = np.append(PSD_binned, np.average(ensemble_ave[i_min-count:i_max+1])) # And the average PSD in each fbin will be... the average PSD in each fbin :P\n",
    "                dPSD = np.append(dPSD, np.sqrt(sum(ensemble_errors[i_min-count:i_max+1]**2))/(i_max-i_min+count))\n",
    "                count=0\n",
    "            else:\n",
    "                freqs_binned = np.append(freqs_binned, (freqs[i_min] + freqs[i_max])/2) # The average frequency in each fbin will then be the bin centre.\n",
    "                PSD_binned = np.append(PSD_binned, np.average(ensemble_ave[i_min:i_max+1])) # And the average PSD in each fbin will be... the average PSD in each fbin :P\n",
    "                dPSD = np.append(dPSD, np.sqrt(sum(ensemble_errors[i_min:i_max+1]**2))/(i_max-i_min)) # If the bin does not have size 1, then the errors are calculated as the quadratic sum of the ensemble errors in the bin.\n",
    "            # else:\n",
    "            #     dPSD = np.append(dPSD, ensemble_errors[i_min]) # If it has size 1, the fbin error is just the ensemble averaged error.\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return freqs_binned, PSD_binned, dPSD\n",
    "\n",
    "def FourierLag(s, h, dt, NfDec, max_seg_period):\n",
    "    \n",
    "    '''Procedure to calculate the Fourier lag as in Uttley (2014), omitting background and poisson error terms as input from simulations.'''\n",
    "    P_s = binned_spectrum(s, dt, NfDec = NfDec, max_seg_period = max_seg_period)[1] # Used later for error calcs.\n",
    "    P_h = binned_spectrum(h, dt, NfDec = NfDec, max_seg_period = max_seg_period)[1]\n",
    "    #print(P_s)\n",
    "    \n",
    "    di = 2 ** int(log2(max_seg_period/dt))\n",
    "    M =  int(len(s)/di)\n",
    "    freqs = abs(fourier.fftfreq(di, dt))[1:int(di/2+1)] # Raw frequencies of the sliced data.\n",
    "    fbins = np.logspace(log10(freqs[0]), log10(freqs[-1]), int(log10(freqs[-1]) - log10(freqs[0])) * NfDec) # We define the logarithmic bins for our output PSD.\n",
    "    # print len(freqs),len(fbins),len(freqs)/(1.0*len(fbins)),int(log10(freqs[-1]) - log10(freqs[0])) \n",
    "    # exit()\n",
    "    #Here we slice up the 'soft' and 'hard' time series as in ensemble_averaging.\n",
    "    h = h[0: M*di]\n",
    "    h.shape = (M, di)\n",
    "    s = s[0: M*di] \n",
    "    s.shape = (M, di)\n",
    "\n",
    "    #Compute the ensemble averaged cross spectra.\n",
    "    \n",
    "    freqs_ens = abs(fourier.fftfreq(di, dt)[1:int(di/2+1)])  # Ensure this is outside the loop\n",
    "\n",
    "    #Compute the ensemble averaged cross spectra\n",
    "    cross_spec = np.zeros((M, int(di/2)), dtype='complex')\n",
    "    for j in range(M):\n",
    "        H = fourier.fft(h[j]) / di\n",
    "        S = fourier.fft(s[j]) / di\n",
    "\n",
    "        cross_0 = (np.conj(S) * H) * di * 2 * dt / (np.average(h[j]) * np.average(s[j]))\n",
    "        cross_spec[j] = cross_0[1:int(di/2+1)]\n",
    "\n",
    "    cross_ens = cross_spec.sum(axis=0) / M\n",
    "\n",
    "    # Split into real and imaginary components\n",
    "    cross_re_ens = real(cross_ens)\n",
    "    cross_im_ens = imag(cross_ens)\n",
    "\n",
    "    #Logarithmically bin the cross spectral components.\n",
    "    freqs = np.array(())\n",
    "    cross_re = np.array((), dtype = 'float')\n",
    "    cross_im = np.array((), dtype = 'float')\n",
    "    \n",
    "    inds = np.digitize(freqs_ens, fbins)\n",
    "    K = np.array(())\n",
    "\n",
    "    #print('inds:', inds)\n",
    "    #print('freqs_ens:', freqs_ens)\n",
    "    \n",
    "    count=0\n",
    "    for i in range(1, inds[-1]):\n",
    "        if i in inds:\n",
    "            i_min, i_max = min(np.argwhere(inds == i))[0], max(np.argwhere(inds==i))[0]\n",
    "            if(i_min==i_max and count==0):\n",
    "                count+=1\n",
    "            elif(count > 0):\n",
    "                freqs = np.append(freqs, (freqs_ens[i_min-count] + freqs_ens[i_max])/2)\n",
    "                cross_re = np.append(cross_re, np.average(cross_re_ens[i_min-count:i_max+1]))\n",
    "                cross_im = np.append(cross_im, np.average(cross_im_ens[i_min-count:i_max+1]))\n",
    "                K = np.append(K, i_max-i_min+count+1)\n",
    "                count=0\n",
    "            else:\n",
    "                freqs = np.append(freqs, (freqs_ens[i_min] + freqs_ens[i_max])/2)\n",
    "                cross_re = np.append(cross_re, np.average(cross_re_ens[i_min:i_max+1]))\n",
    "                cross_im = np.append(cross_im, np.average(cross_im_ens[i_min:i_max+1]))\n",
    "                K = np.append(K, i_max-i_min+1)           \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #From phase lags, Dphi, get time lags, taus.\n",
    "    Dphi = np.arctan2(cross_im, cross_re) #NOT THE ABSOLUTE VALUE!!!\n",
    "    taus = -Dphi / (2*pi*freqs)\n",
    "    #print('P_s:', P_s, 'P_h:', P_h, 'cross_re:', cross_re, 'cross_im:', cross_im)\n",
    "    #Compute errors on Dphi and taus.\n",
    "    gamma2 = (cross_re**2 + cross_im**2) / (P_s* P_h)\n",
    "    \n",
    "    for l in range(len(gamma2)):\n",
    "        if gamma2[l] < 0:\n",
    "            gamma2[l]= 1 / (K[l]*M)\n",
    "    \n",
    "    d1phi = np.sqrt((1.-gamma2)/(2.*gamma2*K*M))\n",
    "    dtaus = d1phi / (2.*pi*freqs)\n",
    "    return Dphi,freqs, taus, dtaus, gamma2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIERAREU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
